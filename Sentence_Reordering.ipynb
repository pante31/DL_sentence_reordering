{"cells":[{"cell_type":"markdown","metadata":{"id":"ElNaMbLnRdHR"},"source":["# Sentence Reconstruction"]},{"cell_type":"markdown","metadata":{"id":"oXr4iGUGRms8"},"source":["The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence.\n","\n","The otuput can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n","\n","\n","CONSTRAINTS:\n","* No pretrained model can be used.\n","* The neural network models should have less the 20M parameters.\n","* No postprocessing should be done (e.g. no beamsearch)\n","* You cannot use additional training data.\n","\n","\n","BONUS PARAMETERS:\n","\n","A bonus of 0-2 points will be attributed to incentivate the adoption of models with a low number of parameters."]},{"cell_type":"markdown","metadata":{"id":"iQ8k-L-WUK7l"},"source":["# Dataset\n","\n","The dataset is composed by sentences taken from the generics_kb dataset of hugging face. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T22:07:09.829818Z","iopub.status.busy":"2024-06-11T22:07:09.829403Z","iopub.status.idle":"2024-06-11T22:07:24.186855Z","shell.execute_reply":"2024-06-11T22:07:24.185600Z","shell.execute_reply.started":"2024-06-11T22:07:09.829786Z"},"id":"nJ02vehGYySk","outputId":"e40e988a-dab7-4d6f-f44c-678273e9dba9","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\n","Requirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"807Wk-ir_bDU"},"source":["Download the dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T22:07:24.189498Z","iopub.status.busy":"2024-06-11T22:07:24.189127Z","iopub.status.idle":"2024-06-11T22:09:01.149485Z","shell.execute_reply":"2024-06-11T22:09:01.148426Z","shell.execute_reply.started":"2024-06-11T22:07:24.189468Z"},"id":"_WjtqA8TrHcS","outputId":"236c477f-7981-454e-cfd1-a19118566134","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e9363ba10564946ac430c14f444cabe","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.64k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e3acbe0e1e9431f90a0a2cdf64ac09b","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f37ccaf6ade463884d8f50a10b29575","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/27.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b041bc5aeaf04258907adc60474488d8","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/1020868 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","from keras.layers import TextVectorization\n","import tensorflow as tf\n","import numpy as np\n","np.random.seed(42)\n","ds = load_dataset('generics_kb',trust_remote_code=True)['train']"]},{"cell_type":"markdown","metadata":{"id":"lAVLfsdc_ej5"},"source":["Filter row with length greater than 8.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["6ac9b8152bba473ab9c22d64f69173b9","d2eb59a45c0e4068a7497bb3a31b188d","ecdfb26b614b490fb8b3c14d606b78b8","01e2428b016d4c6588e8a399ebbbc367","4be629ac0cc444d7ba724e8e54cb68cd","d7272b54af0b42cd91ae6e1f2a8c66b7","ad458b17c52e43a98d9779245b172cb9","c71e6fdef7b74d9285cc4843b0a4889f","fead1879bbf1494592e40405ca9ab6fd","d388b76907324629a8dcf22232fbe368","cc49c1aa52814e8082b2897ef630c5db"]},"execution":{"iopub.execute_input":"2024-06-11T22:09:01.150953Z","iopub.status.busy":"2024-06-11T22:09:01.150641Z","iopub.status.idle":"2024-06-11T22:10:18.096771Z","shell.execute_reply":"2024-06-11T22:10:18.095860Z","shell.execute_reply.started":"2024-06-11T22:09:01.150926Z"},"id":"iznq8xGNt2Zr","outputId":"562e6fca-fbe5-4474-ec0e-463ff964ede6","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6937eaf7654a454ebc5e83e0fa289927","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/1020868 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["ds = ds.filter(lambda row: len(row[\"generic_sentence\"].split(\" \"))>8 )\n","corpus = [ '<start> ' + row['generic_sentence'].replace(\",\",\" <comma>\") + ' <end>' for row in ds ]\n","corpus = np.array(corpus)\n"]},{"cell_type":"markdown","metadata":{"id":"FyYpXLCF_ldR"},"source":["Create a tokenizer and Detokenizer"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:58:35.079980Z","iopub.status.busy":"2024-06-11T22:58:35.079163Z","iopub.status.idle":"2024-06-11T22:58:40.862801Z","shell.execute_reply":"2024-06-11T22:58:40.861596Z","shell.execute_reply.started":"2024-06-11T22:58:35.079939Z"},"id":"T-bE2JpVbU9E","trusted":true},"outputs":[],"source":["tokenizer=TextVectorization( max_tokens=10000, standardize=\"lower_and_strip_punctuation\", encoding=\"utf-8\",) #con il max prende le piu frequenti. ordina i token del vocab dal piu frequente al meno frequente\n","tokenizer.adapt(corpus)\n","\n","class TextDetokenizer:\n","    def __init__(self, vectorize_layer):\n","        self.vectorize_layer = vectorize_layer\n","        vocab = self.vectorize_layer.get_vocabulary()\n","        self.index_to_word = {index: word for index, word in enumerate(vocab)}\n","\n","    def __detokenize_tokens(self, tokens):\n","        def check_token(t):\n","          if t == 3:\n","            s=\"<start>\"\n","          elif t ==2:\n","            s=\"<end>\"\n","          elif t ==7:\n","            s=\"<comma>\"\n","          else:\n","            s=self.index_to_word.get(t, '[UNK]')\n","          return s\n","\n","        return ' '.join([ check_token(token) for token in tokens if token != 0])\n","\n","    def __call__(self, batch_tokens):\n","       return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]\n","\n","\n","\n","detokenizer = TextDetokenizer( tokenizer )\n","sentences = tokenizer( corpus ).numpy()"]},{"cell_type":"markdown","metadata":{"id":"lZ64sns1_pSK"},"source":["Remove from corpus the sentences where any unknow word appears"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.326313Z","iopub.status.busy":"2024-06-11T22:10:26.325894Z","iopub.status.idle":"2024-06-11T22:10:26.389766Z","shell.execute_reply":"2024-06-11T22:10:26.388831Z","shell.execute_reply.started":"2024-06-11T22:10:26.326275Z"},"id":"2LPQtryQz5wh","trusted":true},"outputs":[],"source":["mask = np.sum( (sentences==1) , axis=1) >= 1\n","original_data = np.delete( sentences, mask , axis=0)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T22:10:26.391376Z","iopub.status.busy":"2024-06-11T22:10:26.391039Z","iopub.status.idle":"2024-06-11T22:10:26.398265Z","shell.execute_reply":"2024-06-11T22:10:26.397283Z","shell.execute_reply.started":"2024-06-11T22:10:26.391348Z"},"id":"qYfOscVk7U0r","outputId":"c4be30c6-4b39-4cdc-deb5-399e1409555b","trusted":true},"outputs":[{"data":{"text/plain":["(241236, 28)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["original_data.shape"]},{"cell_type":"markdown","metadata":{"id":"5puiiQ2D_uxa"},"source":["Shuffle the sentences"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.400343Z","iopub.status.busy":"2024-06-11T22:10:26.399620Z","iopub.status.idle":"2024-06-11T22:10:26.411545Z","shell.execute_reply":"2024-06-11T22:10:26.410497Z","shell.execute_reply.started":"2024-06-11T22:10:26.400298Z"},"id":"1ZXLkWB6od0R","trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","\n","class DataGenerator(Sequence):\n","    def __init__(self, data, batch_size=32, shuffle=True, seed=42):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.seed = seed\n","        self.on_epoch_end()\n","\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.data) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        data_batch = np.array([self.data[k] for k in indexes])\n","        #copy of ordered sequences\n","        result = np.copy(data_batch)\n","        #shuffle only the relevant positions for each batch\n","        for i in range(data_batch.shape[0]):\n","          np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n","\n","        return data_batch , result\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.data))\n","        if self.shuffle:\n","            if self.seed is not None:\n","                np.random.seed(self.seed)\n","            np.random.shuffle(self.indexes)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.413421Z","iopub.status.busy":"2024-06-11T22:10:26.412992Z","iopub.status.idle":"2024-06-11T22:10:26.462537Z","shell.execute_reply":"2024-06-11T22:10:26.461626Z","shell.execute_reply.started":"2024-06-11T22:10:26.413387Z"},"trusted":true},"outputs":[],"source":["# Make a random permutation of training and test set\n","np.random.seed(42)\n","# Shuffle the all data\n","shuffled_indices = np.random.permutation(len(original_data))\n","shuffled_data = original_data[shuffled_indices]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.464083Z","iopub.status.busy":"2024-06-11T22:10:26.463726Z","iopub.status.idle":"2024-06-11T22:10:26.477477Z","shell.execute_reply":"2024-06-11T22:10:26.476461Z","shell.execute_reply.started":"2024-06-11T22:10:26.464050Z"},"id":"uNlq1Khx1oH2","trusted":true},"outputs":[],"source":["test_generator = DataGenerator(shuffled_data)\n","x, y = test_generator.__getitem__(1)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T22:10:26.482569Z","iopub.status.busy":"2024-06-11T22:10:26.482173Z","iopub.status.idle":"2024-06-11T22:10:26.493216Z","shell.execute_reply":"2024-06-11T22:10:26.491655Z","shell.execute_reply.started":"2024-06-11T22:10:26.482534Z"},"id":"qR5xwMOn4E88","outputId":"7f7d4cc0-d3a6-4273-cd00-1e0ddb6087cd","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["original:  <start> aggression is common in both male and female rabbits <comma> especially during breeding season <end>\n","shuffled:  <start> common breeding aggression especially rabbits male both and <comma> female is season in during <end>\n","\n","\n","original:  <start> fuel cells differ from other chemical batteries in two major respects <end>\n","shuffled:  <start> from major respects batteries other two cells differ chemical in fuel <end>\n","\n","\n","original:  <start> weather is the condition of the atmosphere over a brief period of time <end>\n","shuffled:  <start> the weather the atmosphere brief is of condition period time a over of <end>\n","\n","\n","original:  <start> crystals can form from vapors <comma> solutions <comma> or molten materials <end>\n","shuffled:  <start> vapors <comma> from materials or form <comma> crystals solutions can molten <end>\n","\n","\n","original:  <start> soap disrupts the membranes of the bacteria <end>\n","shuffled:  <start> disrupts of the soap the bacteria membranes <end>\n","\n","\n","original:  <start> sex cells have half the number of chromosomes as normal body cells <end>\n","shuffled:  <start> body half normal as cells sex have of the cells chromosomes number <end>\n","\n","\n","original:  <start> trees respond effectively to their wounds without the aid of additional chemicals <end>\n","shuffled:  <start> effectively of trees aid the their respond wounds without to additional chemicals <end>\n","\n","\n"]}],"source":["x = detokenizer(x)\n","y = detokenizer(y)\n","\n","for i in range(7):\n","  print(\"original: \", y[i])\n","  print(\"shuffled: \", x[i])\n","  print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"Fo8MazCGBTv3"},"source":["# Metrics"]},{"cell_type":"markdown","metadata":{"id":"G0NOkuO0CfPo"},"source":["Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n","\n","1.  look for the longest substring w between s and p\n","2.  compute |w|/max(|s|,|p|)\n","\n","If the match is exact, the score is 1.\n","\n","When computing the score, you should NOT consider the start and end tokens.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a-aUrdlXDdVf"},"source":["The longest common substring can be computed with the SequenceMatcher function of difflib, that allows a simple definition of our metric."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.495799Z","iopub.status.busy":"2024-06-11T22:10:26.494561Z","iopub.status.idle":"2024-06-11T22:10:26.507947Z","shell.execute_reply":"2024-06-11T22:10:26.506722Z","shell.execute_reply.started":"2024-06-11T22:10:26.495719Z"},"id":"ulpTRdrF_huh","trusted":true},"outputs":[],"source":["from difflib import SequenceMatcher\n","\n","def score(s,p):\n","    match = SequenceMatcher(None, s, p).find_longest_match()\n","    #print(match.size)\n","    return (match.size/max(len(p),len(s)))"]},{"cell_type":"markdown","metadata":{"id":"RB2YfjXNExM-"},"source":["Let's do an example."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.510715Z","iopub.status.busy":"2024-06-11T22:10:26.509621Z","iopub.status.idle":"2024-06-11T22:10:26.520809Z","shell.execute_reply":"2024-06-11T22:10:26.519833Z","shell.execute_reply.started":"2024-06-11T22:10:26.510654Z"},"id":"h17C8bVjEwur","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["your score is  0.5423728813559322\n"]}],"source":["original = \"at first henry wanted to be friends with the king of france\"\n","generated = \"henry wanted to be friends with king of france at the first\"\n","\n","print(\"your score is \",score(original,generated))"]},{"cell_type":"markdown","metadata":{"id":"BET8GqBvFugR"},"source":["The score must be computed as an average of at least 3K random examples taken form the test set."]},{"cell_type":"markdown","metadata":{"id":"4fwo7xj4GBW1"},"source":["# What to deliver"]},{"cell_type":"markdown","metadata":{"id":"i6uITuxOGHfJ"},"source":["You are supposed to deliver a single notebook, suitably commented.\n","The notebook should describe a single model, although you may briefly discuss additional attempts you did.\n","\n","The notebook should contain a full trace of the training.\n","Weights should be made available on request.\n","\n","You must also give a clear assesment of the performance of the model, computed with the metric that has been given to you.\n","\n","# Good work!"]},{"cell_type":"markdown","metadata":{},"source":["## Model used\n","For this task, I implemented a **Transformer** model based on the \"***Attention is All You Need***\" paper. Since the task involved manipulating sequences of natural language, the **Transformer** architecture, due to its efficient handling of dependencies within sequences, was the first choice that came to my mind.\n","\n","The data format provided by the notebook assignment's `DataGenerator`  required some adjustments to match the expected format for the Transformer model. I modified the `DataGenerator` to return a tuple containing two elements:\n","\n","- *X* : Permuted sentence and original ordered sentence (as a tuple)\n","- *y* : Ordered sequence shifted by one position"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.523680Z","iopub.status.busy":"2024-06-11T22:10:26.522693Z","iopub.status.idle":"2024-06-11T22:10:26.540000Z","shell.execute_reply":"2024-06-11T22:10:26.539074Z","shell.execute_reply.started":"2024-06-11T22:10:26.523645Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import Sequence\n","\n","class DataGenerator(Sequence):\n","    def __init__(self, data, batch_size=32, shuffle=True, seed=42):\n","        self.data = data\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.seed = seed\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.data) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        data_batch = np.array([self.data[k] for k in indexes])\n","        #cop of ordered sequences\n","        result = np.copy(data_batch)\n","        for i in range(len(result)):\n","           result[i][result[i] == 2] = 0 \n","        target_data = [np.append(s[1:], [0]) for s in data_batch]\n","        #shuffle only the relevant positions for each batch\n","        for i in range(data_batch.shape[0]):\n","          np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n","\n","        return (np.array(data_batch) , np.array(result)), np.array(target_data)\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.data))\n","        if self.shuffle:\n","            if self.seed is not None:\n","                np.random.seed(self.seed)\n","            np.random.shuffle(self.indexes)"]},{"cell_type":"markdown","metadata":{},"source":["Once the class `DataGenerator` was ready, I used it to create created two separate generators: `train_generator` and `test_generator`. These generators are responsible for preparing and producing batches of data for the training and testing phases of the model, respectively."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.541603Z","iopub.status.busy":"2024-06-11T22:10:26.541220Z","iopub.status.idle":"2024-06-11T22:10:26.564298Z","shell.execute_reply":"2024-06-11T22:10:26.563192Z","shell.execute_reply.started":"2024-06-11T22:10:26.541567Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(28,)\n","(28,)\n","(28,)\n"]}],"source":["train_generator = DataGenerator(shuffled_data[:220000],batch_size=128)\n","test_generator = DataGenerator(shuffled_data[220000:],batch_size=512)\n","x,y = train_generator.__getitem__(1)\n","\n","print(x[0][0].shape,x[1][0].shape,y[0].shape,sep=\"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## **Transformer implementation**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.565865Z","iopub.status.busy":"2024-06-11T22:10:26.565570Z","iopub.status.idle":"2024-06-11T22:10:26.573750Z","shell.execute_reply":"2024-06-11T22:10:26.572655Z","shell.execute_reply.started":"2024-06-11T22:10:26.565840Z"},"trusted":true},"outputs":[],"source":["# This function creates positional encodings for a sequence: it encodes the position of each element in the sequence.\n","\n","def positional_encoding(length, depth):\n","  depth = depth/2\n","\n","  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n","\n","  angle_rates = 1 / (10000**depths)         # (1, depth)\n","  angle_rads = positions * angle_rates      # (pos, depth)\n","\n","  pos_encoding = np.concatenate(\n","      [np.sin(angle_rads), np.cos(angle_rads)],\n","      axis=-1) \n","\n","  return tf.cast(pos_encoding, dtype=tf.float32)\n"]},{"cell_type":"markdown","metadata":{},"source":["### ***Embedding***"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.575397Z","iopub.status.busy":"2024-06-11T22:10:26.575018Z","iopub.status.idle":"2024-06-11T22:10:26.588482Z","shell.execute_reply":"2024-06-11T22:10:26.587537Z","shell.execute_reply.started":"2024-06-11T22:10:26.575364Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from keras import layers\n","\n","\n","# This class implements a layer that does the PositionalEmbedding for the words vectors.\n","\n","class PositionalEmbedding(tf.keras.layers.Layer):\n","  \n","  def __init__(self, vocab_size, d_model):\n","    super().__init__()\n","    self.d_model = d_model\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n","    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n","\n","  def compute_mask(self, *args, **kwargs):\n","    return self.embedding.compute_mask(*args, **kwargs)\n","\n","  def call(self, x):\n","    length = tf.shape(x)[1]\n","    x = self.embedding(x)\n","    # This factor sets the relative scale of the embedding and positonal_encoding.\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x = x + self.pos_encoding[tf.newaxis, :length, :]\n","    return x\n"]},{"cell_type":"markdown","metadata":{},"source":["### ***Attention***"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.590097Z","iopub.status.busy":"2024-06-11T22:10:26.589758Z","iopub.status.idle":"2024-06-11T22:10:26.598222Z","shell.execute_reply":"2024-06-11T22:10:26.597469Z","shell.execute_reply.started":"2024-06-11T22:10:26.590062Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from keras import layers\n","\n","\n","# This class is used as superclass for the class that implement the different Attention mechanisms explained in the paper.\n","\n","class BaseAttention(tf.keras.layers.Layer):\n","  \n","  def __init__(self, **kwargs):\n","    super().__init__()\n","    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n","    self.layernorm = tf.keras.layers.LayerNormalization()\n","    self.add = tf.keras.layers.Add()\n","    "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.599774Z","iopub.status.busy":"2024-06-11T22:10:26.599425Z","iopub.status.idle":"2024-06-11T22:10:26.608029Z","shell.execute_reply":"2024-06-11T22:10:26.607156Z","shell.execute_reply.started":"2024-06-11T22:10:26.599738Z"},"trusted":true},"outputs":[],"source":["# The class above defined is used as a superclss for the following Attention classes:\n","#   CrossAttention, GlobalSelfAttention, CausalSelfAttention\n","\n","class CrossAttention(BaseAttention):\n","  \n","  def call(self, x, context):\n","    attn_output, attn_scores = self.mha(\n","        query=x,\n","        key=context,\n","        value=context,\n","        return_attention_scores=True)\n","    \n","    self.last_attn_scores = attn_scores\n","\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.609337Z","iopub.status.busy":"2024-06-11T22:10:26.609038Z","iopub.status.idle":"2024-06-11T22:10:26.622252Z","shell.execute_reply":"2024-06-11T22:10:26.621275Z","shell.execute_reply.started":"2024-06-11T22:10:26.609312Z"},"trusted":true},"outputs":[],"source":["class GlobalSelfAttention(BaseAttention):\n","  \n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    \n","    return x"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.624228Z","iopub.status.busy":"2024-06-11T22:10:26.623319Z","iopub.status.idle":"2024-06-11T22:10:26.633632Z","shell.execute_reply":"2024-06-11T22:10:26.632578Z","shell.execute_reply.started":"2024-06-11T22:10:26.624200Z"},"trusted":true},"outputs":[],"source":["class CausalSelfAttention(BaseAttention):\n","  \n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x,\n","        use_causal_mask = True)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    \n","    return x\n","  "]},{"cell_type":"markdown","metadata":{},"source":["### ***Feed Forward***\n","The `FeedFowrad` class implements a layer consisisting a Feed Forward layer, consisting of:\n","- Two ***Dense layers***, with a with a non-linear activation function\n","- One ***Dropout layer*** for regularization\n","- One **residual connection**."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.636921Z","iopub.status.busy":"2024-06-11T22:10:26.636612Z","iopub.status.idle":"2024-06-11T22:10:26.644921Z","shell.execute_reply":"2024-06-11T22:10:26.643989Z","shell.execute_reply.started":"2024-06-11T22:10:26.636886Z"},"trusted":true},"outputs":[],"source":["class FeedForward(tf.keras.layers.Layer):\n","  def __init__(self, d_model, dff, dropout_rate=0.1):\n","    super().__init__()\n","    self.seq = tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),\n","      tf.keras.layers.Dense(d_model),\n","      tf.keras.layers.Dropout(dropout_rate)\n","    ])\n","    self.add = tf.keras.layers.Add()\n","    self.layer_norm = tf.keras.layers.LayerNormalization()\n","\n","  def call(self, x):\n","    x = self.add([x, self.seq(x)])\n","    x = self.layer_norm(x) \n","    \n","    return x"]},{"cell_type":"markdown","metadata":{},"source":["### ***Encoder***\n","The implementation of the **Encoder** defined in the \"***Attention is All You Need***\" paper is achieved by creating an `EncoderLayer` consisting of:\n","- One ***Global Attention layer***\n","- One ***FeedForward Layer***\n","\n","What the **Encoder** does is \"_encoding_\" meaning and order through word embeddings, positional encoding and self-attention mechanisms.\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.646459Z","iopub.status.busy":"2024-06-11T22:10:26.646097Z","iopub.status.idle":"2024-06-11T22:10:26.654343Z","shell.execute_reply":"2024-06-11T22:10:26.653430Z","shell.execute_reply.started":"2024-06-11T22:10:26.646429Z"},"trusted":true},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  \n","  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.self_attention = GlobalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x):\n","    x = self.self_attention(x)\n","    x = self.ffn(x)\n","    \n","    return x\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.655753Z","iopub.status.busy":"2024-06-11T22:10:26.655472Z","iopub.status.idle":"2024-06-11T22:10:26.671803Z","shell.execute_reply":"2024-06-11T22:10:26.670628Z","shell.execute_reply.started":"2024-06-11T22:10:26.655729Z"},"trusted":true},"outputs":[],"source":["# The Encoder class use the previsously implemented layers to create the full encoder\n","\n","class Encoder(tf.keras.layers.Layer):\n","  \n","  def __init__(self, *, num_layers, d_model, num_heads,\n","               dff, vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.pos_embedding = PositionalEmbedding(\n","        vocab_size=vocab_size, d_model=d_model)\n","\n","    self.enc_layers = [\n","        EncoderLayer(d_model=d_model,\n","                     num_heads=num_heads,\n","                     dff=dff,\n","                     dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x):\n","    # `x` is token-IDs shape: (batch, seq_len)\n","    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n","\n","    # Add dropout.\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x)\n","\n","    return x  # Shape `(batch_size, seq_len, d_model)`.\n"]},{"cell_type":"markdown","metadata":{},"source":["### ***Decoder***\n","The implementation of the **Decoder** defined in the \"***Attention is All You Need***\" paper is achieved by creating a `DecoderLayer` consisting of:\n","- One ***Causal Self Attention layer***\n","- One ***Cross Attention layer***\n","- One ***FeedForward Layer***\n","\n","The **Dencoder** uses self-attention to understand relationships within the generated sequence so far, and it extracts information from the encoded input by using another attention mechanism; doing this, it incorporates relevant information from the source sequence for each generated word."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.673884Z","iopub.status.busy":"2024-06-11T22:10:26.673415Z","iopub.status.idle":"2024-06-11T22:10:26.685068Z","shell.execute_reply":"2024-06-11T22:10:26.684196Z","shell.execute_reply.started":"2024-06-11T22:10:26.673841Z"},"trusted":true},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,\n","               *,\n","               d_model,\n","               num_heads,\n","               dff,\n","               dropout_rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.causal_self_attention = CausalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.cross_attention = CrossAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x, context):\n","    x = self.causal_self_attention(x=x)\n","    x = self.cross_attention(x=x, context=context)\n","    \n","    self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n","    return x"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.686706Z","iopub.status.busy":"2024-06-11T22:10:26.686092Z","iopub.status.idle":"2024-06-11T22:10:26.705642Z","shell.execute_reply":"2024-06-11T22:10:26.703860Z","shell.execute_reply.started":"2024-06-11T22:10:26.686667Z"},"trusted":true},"outputs":[],"source":["# The Decoder class use the previsously implemented layers to create the full encoder\n","\n","class Decoder(tf.keras.layers.Layer):\n","  \n","  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n","               dropout_rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n","                                             d_model=d_model)\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","    self.dec_layers = [\n","        DecoderLayer(d_model=d_model, num_heads=num_heads,\n","                     dff=dff, dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","\n","    self.last_attn_scores = None\n","\n","  def call(self, x, context):\n","    # `x` is token-IDs shape (batch, target_seq_len)\n","    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n","\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x  = self.dec_layers[i](x, context)\n","\n","    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","    # The shape of x is (batch_size, target_seq_len, d_model).\n","    return x"]},{"cell_type":"markdown","metadata":{},"source":["### ***Transformer***\n","The stucture of the full **Transformer** is the one presented in the paper: the ***Encoder*** and ***Decoder*** previously implemented, are combined toghter, and a ***Dense layer*** is added at the end."]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T22:10:26.707785Z","iopub.status.busy":"2024-06-11T22:10:26.707151Z","iopub.status.idle":"2024-06-11T22:10:26.720804Z","shell.execute_reply":"2024-06-11T22:10:26.719815Z","shell.execute_reply.started":"2024-06-11T22:10:26.707744Z"},"trusted":true},"outputs":[],"source":["#This class implements the full Transformer using the previously implemented Decoder and Encoder, ending with a Dense Layer\n","class Transformer(tf.keras.Model):\n","  \n","  def __init__(self, *, num_layers, d_model, num_heads, dff,\n","               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=input_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=target_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","  def call(self, inputs):\n","    context, x  = inputs\n","\n","    context = self.encoder(context)  # (batch_size, context_len, d_model)\n","\n","    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n","\n","    # Final linear layer output.\n","    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","    try:\n","      del logits._keras_mask\n","    except AttributeError:\n","      pass\n","\n","    # Return the final output and the attention weights.\n","    return logits"]},{"cell_type":"markdown","metadata":{},"source":["### **Training** "]},{"cell_type":"markdown","metadata":{},"source":["After solving all the problems for the implementation of the ***Transformer*** model, the most challenging part became hyperparameter tuning.\n","Through extensive experimentation with various parameter combinations, I identified the following settings that achieved the best results based on the score metric defined in the assignment notebook. "]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:09:54.632407Z","iopub.status.busy":"2024-06-11T23:09:54.631737Z","iopub.status.idle":"2024-06-11T23:09:54.637409Z","shell.execute_reply":"2024-06-11T23:09:54.636297Z","shell.execute_reply.started":"2024-06-11T23:09:54.632373Z"},"trusted":true},"outputs":[],"source":["# Best parameters found:\n","\n","num_layers = 8\n","d_model = 64\n","dff = 128\n","num_heads = 27\n","dropout_rate = 0.1\n","epoch = 6\n"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:09:54.814916Z","iopub.status.busy":"2024-06-11T23:09:54.814399Z","iopub.status.idle":"2024-06-11T23:09:55.071926Z","shell.execute_reply":"2024-06-11T23:09:55.070988Z","shell.execute_reply.started":"2024-06-11T23:09:54.814819Z"},"trusted":true},"outputs":[],"source":["transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=10000,\n","    target_vocab_size=10000,\n","    dropout_rate=dropout_rate)\n"]},{"cell_type":"markdown","metadata":{},"source":["A custom ***Learning Rate Schedule*** was used to allow me to gradually decrease the learning rate as the model improves; this helps it to converge and avoid overfitting."]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:09:55.073743Z","iopub.status.busy":"2024-06-11T23:09:55.073452Z","iopub.status.idle":"2024-06-11T23:09:55.081010Z","shell.execute_reply":"2024-06-11T23:09:55.079994Z","shell.execute_reply.started":"2024-06-11T23:09:55.073717Z"},"trusted":true},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  \n","  def __init__(self, d_model, warmup_steps=4000):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:09:55.181578Z","iopub.status.busy":"2024-06-11T23:09:55.180707Z","iopub.status.idle":"2024-06-11T23:09:55.188512Z","shell.execute_reply":"2024-06-11T23:09:55.187519Z","shell.execute_reply.started":"2024-06-11T23:09:55.181545Z"},"trusted":true},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:09:55.473094Z","iopub.status.busy":"2024-06-11T23:09:55.472704Z","iopub.status.idle":"2024-06-11T23:09:55.481108Z","shell.execute_reply":"2024-06-11T23:09:55.480102Z","shell.execute_reply.started":"2024-06-11T23:09:55.473064Z"},"trusted":true},"outputs":[],"source":["# Loss and Accuracy are computed using a mask\n","\n","def masked_loss(label, pred):\n","  mask = label != 0\n","  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","  loss = loss_object(label, pred)\n","\n","  mask = tf.cast(mask, dtype=loss.dtype)\n","  loss *= mask\n","\n","  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","  \n","  return loss\n","\n","\n","def masked_accuracy(label, pred):\n","  pred = tf.argmax(pred, axis=2)\n","  label = tf.cast(label, pred.dtype)\n","  match = label == pred\n","\n","  mask = label != 0\n","\n","  match = match & mask\n","\n","  match = tf.cast(match, dtype=tf.float32)\n","  mask = tf.cast(mask, dtype=tf.float32)\n","  \n","  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:09:55.973603Z","iopub.status.busy":"2024-06-11T23:09:55.973239Z","iopub.status.idle":"2024-06-11T23:09:55.982028Z","shell.execute_reply":"2024-06-11T23:09:55.980971Z","shell.execute_reply.started":"2024-06-11T23:09:55.973575Z"},"trusted":true},"outputs":[],"source":["transformer.compile(\n","    loss=masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy])\n"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:09:56.196714Z","iopub.status.busy":"2024-06-11T23:09:56.196349Z","iopub.status.idle":"2024-06-11T23:10:06.185158Z","shell.execute_reply":"2024-06-11T23:10:06.184345Z","shell.execute_reply.started":"2024-06-11T23:09:56.196686Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'global_self_attention_8' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'encoder_layer_8' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'causal_self_attention_8' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'decoder_layer_8' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]}],"source":["output = transformer(x)\n"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:10:06.187145Z","iopub.status.busy":"2024-06-11T23:10:06.186827Z","iopub.status.idle":"2024-06-11T23:10:06.219028Z","shell.execute_reply":"2024-06-11T23:10:06.218119Z","shell.execute_reply.started":"2024-06-11T23:10:06.187107Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,355,584</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,937,536</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">650,000</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder_1 (\u001b[38;5;33mEncoder\u001b[0m)             │ ?                      │     \u001b[38;5;34m4,355,584\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder_1 (\u001b[38;5;33mDecoder\u001b[0m)             │ ?                      │     \u001b[38;5;34m7,937,536\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │       \u001b[38;5;34m650,000\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,943,120</span> (49.37 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,943,120\u001b[0m (49.37 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,943,120</span> (49.37 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,943,120\u001b[0m (49.37 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["transformer.summary()\n"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T23:10:06.220611Z","iopub.status.busy":"2024-06-11T23:10:06.220263Z","iopub.status.idle":"2024-06-11T23:10:06.225149Z","shell.execute_reply":"2024-06-11T23:10:06.224264Z","shell.execute_reply.started":"2024-06-11T23:10:06.220578Z"},"trusted":true},"outputs":[],"source":["# Here weights previously computed are loaded in order to continue the optimization without starting over\n","\n","transformer.load_weights('/kaggle/input/weights/transformer_13epochs.weights.h5')\n"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T00:43:10.108864Z","iopub.status.busy":"2024-06-12T00:43:10.108468Z","iopub.status.idle":"2024-06-12T00:51:34.096212Z","shell.execute_reply":"2024-06-12T00:51:34.095363Z","shell.execute_reply.started":"2024-06-12T00:43:10.108832Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","\u001b[1m1718/1718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 146ms/step - loss: 0.3736 - masked_accuracy: 0.8893\n","Epoch 2/2\n","\u001b[1m1718/1718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 146ms/step - loss: 0.3461 - masked_accuracy: 0.8958\n"]}],"source":["# Training of the model\n","\n","transformer.fit(train_generator,epochs=2)\n","transformer.save_weights('transformer15_epochs.weights.h5')\n"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T00:51:34.098539Z","iopub.status.busy":"2024-06-12T00:51:34.098267Z","iopub.status.idle":"2024-06-12T00:51:34.109984Z","shell.execute_reply":"2024-06-12T00:51:34.109094Z","shell.execute_reply.started":"2024-06-12T00:51:34.098515Z"},"trusted":true},"outputs":[],"source":["# Here the trained Transformer is used to reconstruct the order of shuffled sentences.\n","# The function take a batch of sequences with shuffled words and it reorders them.\n","# The setnence creation is achieved by an iterative (autoregressive) loop generating a single token at a time.\n","\n","class Orderer(tf.Module):\n","  \n","  def __init__(self, tokenizers, transformer):\n","    self.tokenizers = tokenizers\n","    self.transformer = transformer\n","\n","  def __call__(self, sentences, max_length=28):\n","    # I see if the input is a tensor\n","    assert isinstance(sentences, tf.Tensor)\n","    if len(sentences.shape) == 0:\n","      sentence = sentences[tf.newaxis]\n","    batch_size = sentences.shape[0]\n","\n","    # I reshape the input to a suitable size\n","    encoder_input = tf.reshape(sentences,[batch_size,28])\n","\n","    # I save the token for the start and the end of the sequence\n","    start_end = self.tokenizers(['<start>',\"<end>\"])\n","    start = start_end[0][tf.newaxis][0]\n","    end = start_end[1][tf.newaxis][0]\n","\n","      \n","    output_array = [[start] for i in range(batch_size)]\n","\n","    for i in tf.range(max_length) :\n","        output = np.reshape(output_array, (batch_size, (i+1)))\n","        predictions = self.transformer([encoder_input, output], training=False)\n","        # Select the last token from the 'seq_len' dimension.\n","        predictions = predictions[:, -1:, :] # Shape (batch_size, 1, vocab_size) •\n","        \n","        predicted_id = tf.argmax(predictions, axis=-1)\n","        \n","        # Concatenate the predicted_id to the output which is given to the\n","        # decoder as its input.\n","        for i in range (batch_size) :\n","            if output_array[i][-1] == end or output_array[i][-1] == 0:\n","                output_array[i].append(output_array[i][-1])\n","                continue\n","            output_array[i].append(predicted_id[i] .numpy())\n","                             \n","    output = np.array(output_array)\n","    # The output shape is (1, tokens)\n","    text = detokenizer(output[:,:, 0])\n","\n","\n","    return text"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T00:51:34.111433Z","iopub.status.busy":"2024-06-12T00:51:34.111086Z","iopub.status.idle":"2024-06-12T00:51:34.124894Z","shell.execute_reply":"2024-06-12T00:51:34.124000Z","shell.execute_reply.started":"2024-06-12T00:51:34.111403Z"},"trusted":true},"outputs":[],"source":["def clean_sentence(x):\n","    x = x.replace('<start>', '').replace('<end>', '').replace('<pad>', '').strip()\n","    return x\n"]},{"cell_type":"markdown","metadata":{},"source":["### **Testing**\n","The model was evaluated using the scoring function provided in the assignment notebook.\n","This folloing lines of code calculate a score for each batch of the testing data. The final score, is then obtained, by computing the average of all these batch scores. "]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-06-12T00:51:34.126735Z","iopub.status.busy":"2024-06-12T00:51:34.126467Z","iopub.status.idle":"2024-06-12T01:04:52.790936Z","shell.execute_reply":"2024-06-12T01:04:52.789927Z","shell.execute_reply.started":"2024-06-12T00:51:34.126711Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["recycling helps conserve natural resources and prevents precious pollution\n","recycling prevents pollution and helps conserve precious natural resources\n","\n","====BATCH OVER====\n","Score as of batch  0 :  0.4625899121482372\n","men are responsible for what goes on during sex\n","men are responsible for what goes on during sex\n","\n","====BATCH OVER====\n","Score as of batch  1 :  0.4747520524006411\n","some people try to deal with stress because they never learn how to avoid stressful situations\n","some people never learn how to deal with stress because they try to avoid stressful situations\n","\n","====BATCH OVER====\n","Score as of batch  2 :  0.4781457651734932\n","houses vary greatly in the levels of radon gas they contain\n","houses vary greatly in the levels of radon gas they contain\n","\n","====BATCH OVER====\n","Score as of batch  3 :  0.4802752260733347\n","employment is the leading source of health insurance coverage\n","employment is the leading source of health insurance coverage\n","\n","====BATCH OVER====\n","Score as of batch  4 :  0.4815696527880692\n","vacuoles are small contractile and numerous lying near the surface\n","contractile vacuoles are small and numerous lying near the surface\n","\n","====BATCH OVER====\n","Score as of batch  5 :  0.48201267686683386\n","plants eliminate higher pores of the surface through the stomata <comma> or <comma> gases on leaves\n","higher plants eliminate gases through the stomata <comma> or pores <comma> on the surface of leaves\n","\n","====BATCH OVER====\n","Score as of batch  6 :  0.48425222106991395\n","software manufacturers design the design of products and the universal responsibility of hardware\n","universal design is the responsibility of the manufacturers of hardware and software products\n","\n","====BATCH OVER====\n","Score as of batch  7 :  0.48552324906222777\n","some animals dissipate heat absorbed by various mechanisms from their surroundings\n","some animals dissipate heat absorbed from their surroundings by various mechanisms\n","\n","====BATCH OVER====\n","Score as of batch  8 :  0.48521996887287133\n","tonsils are lymph glands at the back of the throat\n","tonsils are lymph glands at the back of the throat\n","\n","====BATCH OVER====\n","Score as of batch  9 :  0.4893628809577815\n","silicon technology is an important component of high water valleys industries\n","water is an important component of silicon valleys high technology industries\n","\n","====BATCH OVER====\n","Score as of batch  10 :  0.48971371465723423\n","stars are mostly celestial and hydrogen consisting of celestial objects\n","stars are celestial objects consisting mostly of hydrogen and helium\n","\n","====BATCH OVER====\n","Score as of batch  11 :  0.4868499426963193\n","pups are blind at birth and remain helpless and for roughly half with a year parents\n","pups are blind and helpless at birth and remain with parents for roughly half a year\n","\n","====BATCH OVER====\n","Score as of batch  12 :  0.48762265787762293\n","plants provide big and small animals for solid nourishment\n","plants provide solid nourishment for animals big and small\n","\n","====BATCH OVER====\n","Score as of batch  13 :  0.48888997986895527\n","insects are common among fishes <comma> reptiles <comma> amphibians <comma> and venomous animals\n","venomous animals are common among insects <comma> fishes <comma> amphibians <comma> and reptiles\n","\n","====BATCH OVER====\n","Score as of batch  14 :  0.4891093990237041\n","warts are tiny <comma> rough bumps <comma> often with a hard center <comma> black on the skin\n","warts are rough <comma> hard bumps on the skin <comma> often with a tiny <comma> black center\n","\n","====BATCH OVER====\n","Score as of batch  15 :  0.48853651038521123\n","epiphytes are plants that live on the surface trunks <comma> especially the other branches and of plants\n","epiphytes are plants that live on the surface of other plants <comma> especially the trunks and branches\n","\n","====BATCH OVER====\n","Score as of batch  16 :  0.48845296266058896\n","natural communities are most susceptible to the invasion of one or more by species\n","most natural communities are susceptible to invasion by one or more of the species\n","\n","====BATCH OVER====\n","Score as of batch  17 :  0.48803551219380104\n","some fertilizers contain additional potassium and can be used to be safe on the side\n","some fertilizers contain additional potassium and can be used to be on the safe side\n","\n","====BATCH OVER====\n","Score as of batch  18 :  0.48840826870348614\n","domain sources appear as noise in the frequency of bodies\n","bodies appear as sources of noise in the frequency domain\n","\n","====BATCH OVER====\n","Score as of batch  19 :  0.4881563776667169\n","evaporation is the process by which water converts from liquid to vapor form\n","evaporation is the process by which water converts from liquid to vapor form\n","\n","====BATCH OVER====\n","Score as of batch  20 :  0.48781651835456424\n","music is different from other music forms of church\n","church music is different from other forms of music\n","\n","====BATCH OVER====\n","Score as of batch  21 :  0.48736297110875976\n","birds can get sick at a consequence <comma> and other birds do as do sick up feeders\n","sick birds do show up at feeders <comma> and other birds can get sick as a consequence\n","\n","====BATCH OVER====\n","Score as of batch  22 :  0.48793141757873015\n","cysts remains infectious for prolonged periods in the environment\n","cysts remains infectious for prolonged periods in the environment\n","\n","====BATCH OVER====\n","Score as of batch  23 :  0.4876711317558045\n","some holidays show the public relationship on homes or on businesses in a week to specific days\n","some businesses show a relationship to weather on specific days in the week or on public holidays\n","\n","====BATCH OVER====\n","Score as of batch  24 :  0.4878629131259194\n","indian medicine is used by many american tribes\n","some medicine is used by many american indian tribes\n","\n","====BATCH OVER====\n","Score as of batch  25 :  0.48815269899561337\n","sulfur is a pale <comma> odorless <comma> brittle solid <comma> which is insoluble in yellow water\n","sulfur is a pale yellow <comma> odorless <comma> brittle solid <comma> which is insoluble in water\n","\n","====BATCH OVER====\n","Score as of batch  26 :  0.4878142583754302\n","toxic wastes are harmful or fatal when ingested or absorbed\n","toxic wastes are harmful or fatal when ingested or absorbed\n","\n","====BATCH OVER====\n","Score as of batch  27 :  0.48734834236690966\n","forgiveness is an event <comma> the ability to look through an past event\n","forgiveness is the ability to look through an event <comma> past an event\n","\n","====BATCH OVER====\n","Score as of batch  28 :  0.4872027806920268\n","many factors influence the selection and use of contraceptives\n","many factors influence the selection and use of contraceptives\n","\n","====BATCH OVER====\n","Score as of batch  29 :  0.48734717590643994\n","albatrosses take care of their young chicks until they have grown enough to defend themselves\n","albatrosses take care of their young chicks until they have grown enough to defend themselves\n","\n","====BATCH OVER====\n","Score as of batch  30 :  0.4879080978628393\n","freedom of speech is different from religion and distinct of freedom\n","freedom of religion is different and distinct from freedom of speech\n","\n","====BATCH OVER====\n","Score as of batch  31 :  0.48832199302897816\n","skin first represents the bodys line of defense against pathogens\n","skin represents the bodys first line of defense against pathogens\n","\n","====BATCH OVER====\n","Score as of batch  32 :  0.48862475985249015\n","statistics argue and analyze individual fans and sports fans about performance to conduct and love\n","sports fans love to analyze and argue about and discuss individual and team performance statistics\n","\n","====BATCH OVER====\n","Score as of batch  33 :  0.48847537717480105\n","cheetahs are active in the early morning or late evening <comma> and hunt during the day\n","cheetahs are active during the day <comma> and hunt in the early morning or late evening\n","\n","====BATCH OVER====\n","Score as of batch  34 :  0.48837649939645755\n","total ozone means the total amount of ozone to a certain linear point above the sun\n","total ozone means the total amount of ozone above a certain point linear to the sun\n","\n","====BATCH OVER====\n","Score as of batch  35 :  0.48860501380894683\n","depth is the area of the area in which image appears to be in focus\n","depth of field is the area in which the image appears to be in focus\n","\n","====BATCH OVER====\n","Score as of batch  36 :  0.4884899293247433\n","occasional pores occur between the inner and outer membranes forming the nuclear connections\n","occasional connections occur between the outer and inner membranes forming the nuclear pores\n","\n","====BATCH OVER====\n","Score as of batch  37 :  0.4881389276831414\n","most people occur as a building or entering injuries as leaving\n","most injuries occur as people are entering or leaving a building\n","\n","====BATCH OVER====\n","Score as of batch  38 :  0.4881830351035244\n","children can practice the mirror of their bodies in a looking while looking parts\n","children can practice naming the parts of their bodies while looking in a mirror\n","\n","====BATCH OVER====\n","Score as of batch  39 :  0.488294066915671\n","medical service is one of the most important functions of any prevention of military disease\n","prevention of disease is one of the most important functions of any military medical service\n","\n","====BATCH OVER====\n","Score as of batch  40 :  0.488309488531895\n","mineral minerals are some of the most important needs <comma> yet the body deficiency is common nutrients\n","minerals are some of the most important nutrients the body needs <comma> yet mineral deficiency is common\n","\n","====BATCH OVER====\n","Score as of batch  41 :  1.0119143069551473\n","\n","====ALL OVER====\n","Final score:  0.48832632405708937\n"]}],"source":["total_test_size = 0\n","score_ = 0\n","orderer=Orderer(tokenizer,transformer)\n","i = 0\n","\n","for batch in test_generator:\n","    x,y = batch\n","    score_batch_size = x[0].shape[0]\n","    if score_batch_size == 0:\n","        break\n","    total_test_size = total_test_size + score_batch_size\n","    y_pred = orderer(tf.constant(x[0]))\n","    b_score = 0                   # score associated with each batch\n","\n","    pred_sentences = y_pred\n","    original_sentences = detokenizer(x[1])\n","    \n","    print(clean_sentence(pred_sentences[0]),clean_sentence(original_sentences[0]), sep=\"\\n\")\n","\n","    for j in range(score_batch_size) :\n","        b_score += score(clean_sentence(original_sentences[j]), clean_sentence(pred_sentences[j]))\n","\n","    score_ += b_score\n","    print(\"\\n====BATCH OVER====\")\n","    print(\"Score as of batch \", i, \": \", score_/((i+1)*score_batch_size))\n","    i = i + 1\n","\n","score_ = score_/total_test_size\n","print(\"\\n====ALL OVER====\")\n","print(\"Final score: \", score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5195111,"sourceId":8668878,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":53771,"sourceId":64478,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01e2428b016d4c6588e8a399ebbbc367":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d388b76907324629a8dcf22232fbe368","placeholder":"​","style":"IPY_MODEL_cc49c1aa52814e8082b2897ef630c5db","value":" 1020868/1020868 [00:25&lt;00:00, 32940.36 examples/s]"}},"4be629ac0cc444d7ba724e8e54cb68cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ac9b8152bba473ab9c22d64f69173b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2eb59a45c0e4068a7497bb3a31b188d","IPY_MODEL_ecdfb26b614b490fb8b3c14d606b78b8","IPY_MODEL_01e2428b016d4c6588e8a399ebbbc367"],"layout":"IPY_MODEL_4be629ac0cc444d7ba724e8e54cb68cd"}},"ad458b17c52e43a98d9779245b172cb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c71e6fdef7b74d9285cc4843b0a4889f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc49c1aa52814e8082b2897ef630c5db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2eb59a45c0e4068a7497bb3a31b188d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7272b54af0b42cd91ae6e1f2a8c66b7","placeholder":"​","style":"IPY_MODEL_ad458b17c52e43a98d9779245b172cb9","value":"Filter: 100%"}},"d388b76907324629a8dcf22232fbe368":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7272b54af0b42cd91ae6e1f2a8c66b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecdfb26b614b490fb8b3c14d606b78b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c71e6fdef7b74d9285cc4843b0a4889f","max":1020868,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fead1879bbf1494592e40405ca9ab6fd","value":1020868}},"fead1879bbf1494592e40405ca9ab6fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":4}
